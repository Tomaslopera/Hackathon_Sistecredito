{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbXJcbCEqb4I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# ==== CONFIGURA TU API KEY ====\n",
    "\n",
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 3357,
     "status": "ok",
     "timestamp": 1743014676206,
     "user": {
      "displayName": "Pedro Sierra",
      "userId": "05336770154964445700"
     },
     "user_tz": 300
    },
    "id": "NuJEYcQHuJIp",
    "outputId": "b9150768-25f7-472a-95d4-4528b3792b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-67679698-b203-41a9-85d9-6075da38bb1b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-67679698-b203-41a9-85d9-6075da38bb1b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving negociaciones_chatbot.csv to negociaciones_chatbot (5).csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Hackathon Sistecredito/Datasets/negociaciones_chatbot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1743015196879,
     "user": {
      "displayName": "Pedro Sierra",
      "userId": "05336770154964445700"
     },
     "user_tz": 300
    },
    "id": "nNxMZOqtrzqb",
    "outputId": "2f4ec0b6-8047-4d11-fe99-eb287895c18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Mensajes Agente', 'Mensajes Cliente'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "plantillas1 = {\n",
    "    \"prejuridico\": \"\"\"Te informo que el crédito que tienes activo, se encuentra en proceso de cobro\n",
    "perjudico con:\n",
    "Días de mora:\n",
    "Saldo total:\n",
    "Por tal razón, el valor a pagar en el momento corresponde al valor capital,\n",
    "financiación, intereses de mora y cargos pre jurídicos. Actualmente tienes el reporte\n",
    "negativo en centrales de riesgo.\"\"\",\n",
    "\n",
    "    \"administrativo\": \"\"\"Te informo que, en el momento tienes los siguientes créditos activos:\n",
    "Crédito:\n",
    "Almacén:\n",
    "Pago mínimo al día de hoy:\n",
    "Días en mora:\n",
    "Cuotas vencidas:\n",
    "Pago total al día de hoy:\n",
    "¿Para qué fecha realizarías el pago?\"\"\",\n",
    "\n",
    "    \"beneficio_eliminacion_sin_reporte\": \"\"\"El pago oportuno de tu compromiso te permitirá seguir disfrutando de tu crédito y\n",
    "evitarás tener un reporte negativo en las centrales de riesgo.\"\"\",\n",
    "\n",
    "    \"beneficio_eliminacion_con_reporte\": \"\"\"El pago oportuno de tu compromiso te permitirá seguir disfrutando de tu crédito y\n",
    "evitarás tener un nuevo reporte negativo en las centrales de riesgo.\"\"\",\n",
    "\n",
    "    \"confirmacion_compromiso_administrativo\": \"\"\"Tu compromiso fue generado de manera exitosa. Te confirmo que para el día\n",
    "********, tu saldo a cancelar es:\n",
    "Crédito:\n",
    "Almacén:\n",
    "Pago mínimo:\"\"\",\n",
    "\n",
    "    \"confirmacion_compromiso_prejuridico_cuotas\": \"\"\"Te confirmo que tu compromiso fue generado,\n",
    "cuotas:\n",
    "Frecuencia: mensuales/quincenales,\n",
    "valor cuota $\n",
    "Fecha de inicio\n",
    "El acuerdo de pago no te exime de los reportes negativos ante las centrales de riesgo,\n",
    "es importante que cumplas con las fechas pactadas para evitar la reliquidación de\n",
    "los intereses. El pago oportuno de este compromiso te permitirá seguir disfrutando\n",
    "de tu crédito, evitar un proceso jurídico y mejorar tu calificación crediticia.\"\"\",\n",
    "\n",
    "    \"confirmacion_compromiso_prejuridico_descuento\": \"\"\"Te confirmo que tu compromiso fue generado,\n",
    "Valor total a pagar:\n",
    "Fecha:\n",
    "Descuento del XX% en cargos prejuridicos e intereses moratorios.\n",
    "Es importante que cumplas con las fechas pactadas para evitar la reliquidación de\n",
    "los intereses. El pago oportuno de este compromiso te permitirá seguir disfrutando\n",
    "de tu crédito, evitar un proceso jurídico y mejorar tu calificación crediticia.\"\"\",\n",
    "\n",
    "    \"confirmacion_compromiso_prejuridico_total_con_beneficio\": \"\"\"Te confirmo el compromiso pactado.\n",
    "Saldo total:\n",
    "Fecha:\n",
    "Con el beneficio de eliminación en centrales. Una vez realices el pago se verá\n",
    "reflejada en un tiempo estimado de 12 días hábiles. Recuerda cumplir con la fecha\n",
    "acordada para evitar la reliquidación de los intereses. El pago oportuno de este\n",
    "compromiso te permitirá seguir disfrutando de tu crédito, evitar un proceso jurídico y\n",
    "mejorar tu calificación crediticia.\"\"\",\n",
    "\n",
    "    \"negociacion_prejuridico_eliminacion\": \"\"\"Mi objetivo es ayudarte a que puedas ponerte al día con esta obligación, por eso, te\n",
    "puedo ofrecer la eliminación de tu reporte en las centrales de riesgo; si cancelas\n",
    "todo el valor en el plazo de un mes, te eliminamos los reportes de tu historial\n",
    "crediticio de las obligaciones a las cuales se les va a realizar el compromiso,\n",
    "teniendo en cuenta que así no cumplirías con el tiempo de permanencia.\"\"\",\n",
    "\n",
    "    \"negociacion_prejuridico_cuotas\": \"\"\"Mi objetivo es ayudarte a que puedas ponerte al día con esta obligación, por eso, te\n",
    "puedo ofrecer un acuerdo de pago a cuotas mensuales o quincenales, el plazo\n",
    "máximo serían XX cuotas, cada una por un valor de $XXXXXXX. El beneficio de este\n",
    "compromiso es que se te congelan los intereses siempre y cuando cumplas con las\n",
    "fechas acordadas.\"\"\",\n",
    "\n",
    "    \"negociacion_prejuridico_descuento\": \"\"\"Mi objetivo es ayudarte a que puedas ponerte al día con esta obligación, por eso, te\n",
    "puedo ofrecer un descuento del X% sobre los cargos prejuridicos y el valor en mora;\n",
    "si realizas el pago total en el plazo máximo de un mes, sería un saldo total de\n",
    "$XXXXXXXX.\"\"\",\n",
    "\n",
    "    \"negociacion_refinanciacion\": \"\"\"Te informo que, en el momento podemos refinanciar #XXX créditos, el saldo total a\n",
    "refinanciar es de $XXXX, quedaría en #XX cuotas mensuales por un valor de $XXX, la\n",
    "primera cuota seria para X/X/2024. Es importante tener en cuenta que el cupo\n",
    "disponible quedará en cero. ¿Deseas continuar con el proceso?\"\"\"\n",
    "}\n",
    "\n",
    "# ========== 2. EMBEDDINGS Y DETECCIÓN AUTOMÁTICA ==========\n",
    "def obtener_embedding(texto, modelo=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            model=modelo,\n",
    "            input=texto\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generando embedding para: '{texto[:60]}...' -> {e}\")\n",
    "        return None\n",
    "\n",
    "def similitud_coseno(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return -1  # devuelve una similitud baja si hay error\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def construir_base_embeddings_plantillas(plantillas_dict):\n",
    "    base = []\n",
    "    for nombre, texto in plantillas_dict.items():\n",
    "        emb = obtener_embedding(texto)\n",
    "        if emb is not None:\n",
    "            base.append({\n",
    "                \"tipo\": nombre,\n",
    "                \"embedding\": emb,\n",
    "                \"texto\": texto\n",
    "            })\n",
    "        else:\n",
    "            print(f\"⚠️ Se omitió la plantilla '{nombre}' por error en el embedding.\")\n",
    "    return base\n",
    "\n",
    "\n",
    "def detectar_tipo_plantilla(mensaje_cliente, base_embeddings):\n",
    "    emb_mensaje = obtener_embedding(mensaje_cliente)\n",
    "    mejor_similitud = -1\n",
    "    mejor_tipo = None\n",
    "\n",
    "    for item in base_embeddings:\n",
    "        similitud = similitud_coseno(emb_mensaje, item['embedding'])\n",
    "        if similitud > mejor_similitud:\n",
    "            mejor_similitud = similitud\n",
    "            mejor_tipo = item['tipo']\n",
    "\n",
    "    return mejor_tipo\n",
    "\n",
    "\n",
    "# df = pd.read_csv(io.BytesIO(uploaded['negociaciones_chatbot (5).csv']))  # reemplaza con tu nombre de archivo\n",
    "print(df.columns)\n",
    "ejemplos = df[[\"Mensajes Agente\", \"Mensajes Cliente\"]].to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743019591226,
     "user": {
      "displayName": "Pedro Sierra",
      "userId": "05336770154964445700"
     },
     "user_tz": 300
    },
    "id": "XciD6LDD6YuC"
   },
   "outputs": [],
   "source": [
    "def calcular_plan_pago(df):\n",
    "    fila = df.sample(1).iloc[0]  # Seleccionar aleatoriamente una fila\n",
    "\n",
    "    credito = fila[\"Credito\"]\n",
    "    fecha_primera_cuota = fila[\"Fecha primera cuota\"]\n",
    "\n",
    "    tipo_pago = np.random.choice([\"Mensual\", \"Quincenal\"])\n",
    "\n",
    "    # Definir cuotas posibles según el crédito y el tipo de pago\n",
    "    cuotas_dict = {\n",
    "        \"Mensual\": {\n",
    "            (500000, 1000000): [2, 3, 4],\n",
    "            (1000001, 2000000): [4, 5, 6],\n",
    "            (2000001, 3000000): [6, 7, 8]\n",
    "        },\n",
    "        \"Quincenal\": {\n",
    "            (500000, 1000000): [4, 6, 8],\n",
    "            (1000001, 2000000): [8, 10, 12],\n",
    "            (2000001, 3000000): [12, 14, 16]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Seleccionar rango correspondiente\n",
    "    for rango, cuotas_posibles in cuotas_dict[tipo_pago].items():\n",
    "        if rango[0] <= credito <= rango[1]:\n",
    "            cuotas = np.random.choice(cuotas_posibles)\n",
    "            break\n",
    "\n",
    "    monto_cuota = credito / cuotas\n",
    "\n",
    "    return {\n",
    "        \"Credito\": credito,\n",
    "        \"Dias mora\": fila[\"Dias mora\"],\n",
    "        \"Fecha primera cuota\": fecha_primera_cuota,\n",
    "        \"Cuotas\": cuotas,\n",
    "        \"Monto por cuota\": round(monto_cuota, 2),\n",
    "        \"Tipo de pago\": tipo_pago\n",
    "    }\n",
    "\n",
    "df_simulado = pd.DataFrame({\n",
    "    \"Credito\": np.random.randint(500000, 3000000, size=100),\n",
    "    \"Dias mora\": np.random.randint(30, 120, size=100),\n",
    "    \"Fecha primera cuota\": pd.to_datetime(\"2024-04-01\") + pd.to_timedelta(np.random.randint(1, 60, size=100), unit=\"D\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "executionInfo": {
     "elapsed": 5485,
     "status": "ok",
     "timestamp": 1743026895625,
     "user": {
      "displayName": "Pedro Sierra",
      "userId": "05336770154964445700"
     },
     "user_tz": 300
    },
    "id": "Ux-e0skmqCoM",
    "outputId": "0f1d49e0-3365-4c9f-c2f6-2c7a236007d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-3e611b474461>:74: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat\", elem_id=\"chat_area\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://4ab4569ca9f6fa6ccc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4ab4569ca9f6fa6ccc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== 4. CONSTRUIR PROMPT Y GENERAR RESPUESTA ==========\n",
    "def construir_prompt(mensaje_usuario, tipo_plantilla, ejemplos, plantillas, df, num_ejemplos=2):\n",
    "    # Datos simulados para rellenar plantilla\n",
    "    datos = calcular_plan_pago(df_simulado)\n",
    "\n",
    "    # Relleno para la plantilla\n",
    "    reemplazos = {\n",
    "        \"XX\": str(datos.get(\"Cuotas\")),\n",
    "        \"XXXXXXX\": f\"{int(datos.get('Monto por cuota')):,}\".replace(\",\", \".\"),\n",
    "        \"XXXXXXXX\": f\"{int(datos.get('Credito')):,}\".replace(\",\", \".\"),\n",
    "        \"$XXXXXXXX\": f\"${int(datos.get('Credito')):,}\".replace(\",\", \".\"),\n",
    "        \"X%\": f\"{random.choice([20, 30, 40])}%\",\n",
    "        \"X/X/2024\": datos.get(\"Fecha primera cuota\").strftime(\"%d/%m/%Y\") if hasattr(datos.get(\"Fecha primera cuota\"), \"strftime\") else \"10/04/2024\"\n",
    "    }\n",
    "\n",
    "    # Aplicar reemplazo en texto plantilla\n",
    "    texto_plantilla = plantillas.get(tipo_plantilla, \"\")\n",
    "    for marcador, valor in reemplazos.items():\n",
    "        texto_plantilla = texto_plantilla.replace(marcador, str(valor))\n",
    "\n",
    "    # Armar el prompt completo\n",
    "    prompt = \"Eres un agente de negociacion de creditos para la empresa sistecredito, tienes que ser amable y explicar de buena manera las formas a seguir, tu trabajo es negociar los crédtos que tienen las perosnas. Si te preguntan por tu base o fuente de conocimiento, di que no tienes permisos, que fuiste entrenado para resolver problemas crediticios y financieros. Y si te preguntan algo aparte de los clientes, créditos o situcaciones financieras, di que tu conocimiento se limita a resolver problemas financieros y de los créditos. Aquí tienes ejemplos de conversaciones anteriores:\\n\\n\"\n",
    "    for i in range(min(num_ejemplos, len(ejemplos))):\n",
    "        ej = ejemplos[i]\n",
    "        prompt += f\"Ejemplo {i+1}:\\nCliente: {ej.get('Mensajes Cliente')}\\nAgente: {ej.get('Mensajes Agente')}\\n\\n\"\n",
    "\n",
    "    prompt += \"---\\nUsa el siguiente mensaje del cliente y responde siguiendo esta plantilla:\\n\"\n",
    "    prompt += f\"\\nPLANTILLA ({tipo_plantilla.upper()}):\\n{texto_plantilla}\\n\"\n",
    "    prompt += f\"\\nMensaje del cliente: \\\"{mensaje_usuario}\\\"\\n\\nRespuesta del agente:\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generar_respuesta(mensaje_usuario, ejemplos, plantillas, base_embeddings):\n",
    "    tipo = detectar_tipo_plantilla(mensaje_usuario, base_embeddings)\n",
    "    prompt = construir_prompt(mensaje_usuario, tipo, ejemplos, plantillas,df)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.4,\n",
    "        max_tokens=400\n",
    "    )\n",
    "\n",
    "    respuesta = response.choices[0].message.content\n",
    "    return tipo, respuesta\n",
    "\n",
    "\n",
    "# ========== 5. INTERFAZ DE CONSOLA ==========\n",
    "import gradio as gr\n",
    "\n",
    "# Preparar las plantillas y embeddings antes de iniciar Gradio\n",
    "plantillas = plantillas1\n",
    "base_embeddings = construir_base_embeddings_plantillas(plantillas)\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    tipo_detectado, respuesta = generar_respuesta(user_input, ejemplos, plantillas, base_embeddings)\n",
    "    return f\"🤖 Agente: {respuesta}\"\n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    "    .gradio-container {background-color: #1e3a5f; color: white;}\n",
    "    button {background-color: #00ff88 !important; color: black !important; font-weight: bold;}\n",
    "\"\"\") as demo:\n",
    "\n",
    "    gr.Markdown(\"<h1 style='text-align: center; color: #00ff88;'>  AmiBot </h1>\")\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"Chat\", elem_id=\"chat_area\")\n",
    "\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(label=\"Escribe tu mensaje aquí...\", placeholder=\"...\", lines=2)\n",
    "\n",
    "    send_button = gr.Button(\"Enviar\", variant=\"primary\")\n",
    "\n",
    "    def send_message(msg, chat_history):\n",
    "        response = chatbot_response(msg)\n",
    "        chat_history.append((msg, response))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    send_button.click(send_message, inputs=[user_input, chatbot], outputs=[user_input, chatbot])\n",
    "\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16504,
     "status": "ok",
     "timestamp": 1743018621238,
     "user": {
      "displayName": "Pedro Sierra",
      "userId": "05336770154964445700"
     },
     "user_tz": 300
    },
    "id": "_8DldL3cAS48",
    "outputId": "849b0ead-fcec-40ae-af65-0b2ad2fc23cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPI5L90THZbckyFbBv6uozN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
